# 一些分析

## 实验

- 1、直接baseline：14W
- 2、baseline把100w个数据改成200w个数据：13W
- 3、处理100种运单：4.3W
- 4、处理1000种运单：4.5W
  - 增加运单却mse增加？
    - 1、可能是迭代的次数不够，没训练到位
    - 2、有很多垃圾数据影响(可能性较大)
- 5、处理20种运单：3.6W
  - 迷惑？
    - 1、垃圾数据太多？
- 6、处理“下采样数据版本1”，-->16894条数据：5.2W
- 7、把6的mse改成越小越好，并迭代2000次：23W
- 8、把7改成迭代100次：22W



通过上述实验得到结论，这次比赛的要点就在于数据集和测试集的分布不同

- 答案的时间间隔大概在[18,20]之间集中
  - 第3个实验得到的时间间隔在[19.6,19.7]之间
  - 第5个实验得到时间间隔就是18.0
- 分布差距很大，如果不改变分布，会越训练效果越差
  - 第7个实验得到的时间间隔集中在[0,7]，mu=4.06，sigma=3.36

- 9、把训练集强行对齐测试集的高斯分布，迭代3000次，mse也是越小越好：4.6W
  - 线下就在训练集上的mse大概200多





## 之后的处理的打算

### 2020.6.7

- 可以参照海洋那个比赛，对经纬度处理
- 通过聚类的方式找到测试数据的相似类来训练
- 增加特征
  - 像洋流，天气之类的，不过预计影响不大
  - 路由之类的
  - 物理学特征？

## 2020.6.8

- 线下搞个验证集
- 新建一个多分类任务预测航线目标港口
- 直接把训练集按照测试集的大小划分，来是分布相同



# 特征的处理
(21157, 24)  #原
(16894, 23)  #下采样一号
(16671, 23)  #扔掉日期<= 1天的   线下同分布mse：380.285
(16615, 23)  #再扔掉运单号数量<=30的    线下同分布mse：371.911

